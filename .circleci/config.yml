version: 2.1

# Use the kubernetes orb to facilitate controlling our cluster
orbs:
  kubernetes: circleci/kubernetes@1.3.1

jobs:
  # lint: Lints the codebase using the tighten/duster Laravel lint tool. We
  # focus on the core Laravel Pint linting only.
  lint:
    docker:
      - image: cimg/php:8.2.8
    steps:
      - checkout
      - run:
          name: Install composer dependencies
          command: |
            composer install
      - run:
          name: Perform linting
          command: |
            ./vendor/bin/duster lint -u pint
  # build-image: Builds the Docker image and pushes to the registry
  build-image:
    docker:
      - image: cimg/aws:2023.07
    steps:
      - checkout
      - setup_remote_docker
      - run:
          name: 'Build docker image'
          command: |
            docker build -t capstone-welcome-app:build-${CIRCLE_WORKFLOW_ID:0:7} .
      - run:
          name: 'Login to AWS container registry'
          command: |
            aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 928265084040.dkr.ecr.us-east-1.amazonaws.com
      - run:
          name: 'Tag image and push to registry'
          command: |
            ## We tag both the exact build and also a 'latest' tag so we don't have to specify the build ID in out kubernetes deployment.yml
            docker tag capstone-welcome-app:build-${CIRCLE_WORKFLOW_ID:0:7} 928265084040.dkr.ecr.us-east-1.amazonaws.com/capstone-welcome-app:build-${CIRCLE_WORKFLOW_ID:0:7}
            docker push 928265084040.dkr.ecr.us-east-1.amazonaws.com/capstone-welcome-app:build-${CIRCLE_WORKFLOW_ID:0:7}
            docker tag capstone-welcome-app:build-${CIRCLE_WORKFLOW_ID:0:7} 928265084040.dkr.ecr.us-east-1.amazonaws.com/capstone-welcome-app:latest
            docker push 928265084040.dkr.ecr.us-east-1.amazonaws.com/capstone-welcome-app:latest
  # configure-infrastructure: Ensure our EKS cluster exists and is ready to use
  configure-infrastructure:
    docker:
      - image: cimg/aws:2023.07
    steps:
      - checkout
      - run:
          name: 'Create / update VPC for EKS cluster from template'
          command: |
            aws cloudformation deploy \
              --stack-name capstone-welcome-app-eks-vpc \
              --template-file .circleci/cloudformation/eks-vpc.yml
      - run:
          name: 'Create / update EKS cluster from template'
          command: |
            ## If we're running outside of a workflow (i.e. locally) then we
            ## override the PublicCIDR so our cluster API is only accessible
            ## from the local machine. The original idea here was to ensure
            ## we only ever allow the current host to access the API endpoint,
            ## however I then split out the kubectl steps to the separate
            ## 'deploy' job which causes this approach to fail as that job
            ## runs in a separate container which could be run on a completely
            ## different host when run on CircleCI.
            if [ -z "${CIRCLE_WORKFLOW_ID:0:7}" ]; then
              aws cloudformation deploy \
                --stack-name capstone-welcome-app-eks-cluster \
                --template-file .circleci/cloudformation/eks-cluster.yml \
                --parameter-overrides PublicCIDR=$(curl -s http://checkip.amazonaws.com)/32
            else
              aws cloudformation deploy \
                --stack-name capstone-welcome-app-eks-cluster \
                --template-file .circleci/cloudformation/eks-cluster.yml
            fi
          # We increase the timeout for this step as during the first run when
          # infrastructure is being created this step will be slow, however in
          # normal runs where we don't change the cloudformation yaml we only
          # expect the PublicCIDR to change, which is a much smaller changeset
          # that should apply quite quickly.
          no_output_timeout: 30m
      - run:
          name: 'Create / update EKS nodegroup from template'
          command: |
            aws cloudformation deploy \
              --stack-name capstone-welcome-app-eks-nodegroup \
              --template-file .circleci/cloudformation/eks-nodes.yml
          no_output_timeout: 30m
  # deploy: Deploys our app by creating / updating
  deploy:
    docker:
      - image: cimg/aws:2023.07
    steps:
      - checkout
      - kubernetes/install-kubectl
      - run:
          name: Configure kubectl to talk to EKS cluster
          command: |
            aws eks update-kubeconfig \
              --name CapstoneWelcomeAppProd
      - run:
          name: Login in to container registry and create/edit kubernetes registry credentials secret
          command: |
            ecr_password_token=$(aws ecr get-login-password | cut -d' ' -f6)
            if kubectl get secrets capstone-registry-credentials; then
              ## Seems easier to delete and recreate a secret rather than editing it
              kubectl delete secret capstone-registry-credentials
            fi
            kubectl create secret docker-registry capstone-registry-credentials \
              --docker-server=https://928265084040.dkr.ecr.us-east-1.amazonaws.com \
              --docker-username=AWS \
              --docker-password=$ecr_password_token
      - run:
          name: Create/edit app secrets
          command: |
            if kubectl get secrets capstone-app-env; then
              kubectl delete secret capstone-app-env
            fi
            ## For a Laravel app we need to specify the app key as a minimum. For a real app
            ## we would also have other secrets such as db credentials etc
            kubectl create secret generic capstone-app-env \
              --from-literal=app-key=${LARAVEL_APP_KEY}
      - run:
          name: Ensure deployment and service exist
          command: |
            if ! kubectl get deployments capstone-welcome-app-deployment; then
              kubectl apply -f .circleci/kubernetes/deployment.yml
              ## This will create an Amazon Elastic Load Balancer that reverse proxies our app
              kubectl expose deployment/capstone-welcome-app-deployment --type="LoadBalancer" --port 80
            fi
      - run:
          name: Perform rolling update
          command: |
            kubectl set image deployments/capstone-welcome-app-deployment 928265084040.dkr.ecr.us-east-1.amazonaws.com/capstone-welcome-app:build-${CIRCLE_WORKFLOW_ID:0:7}

workflows:
  default:
    jobs:
      - lint
      - build-image:
          requires: [lint]
      - configure-infrastructure
      - deploy:
          requires: [build-image, configure-infrastructure]
